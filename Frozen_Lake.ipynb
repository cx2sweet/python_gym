{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b603c9a",
   "metadata": {},
   "source": [
    "https://github.com/openai/gym/wiki/FrozenLake-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861ddaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env=gym.make('FrozenLake-v0')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4a9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "action_space_size=env.action_space.n\n",
    "state_space_size=env.observation_space.n\n",
    "\n",
    "q_table=np.zeros((state_space_size,action_space_size))\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7c24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes=15000\n",
    "max_steps_per_episode=99\n",
    "\n",
    "learning_rate=0.8\n",
    "discount_rate=0.95\n",
    "\n",
    "exploration_rate=1\n",
    "max_exploration_rate=1\n",
    "min_exploration_rate=.01\n",
    "exploration_decay_rate=.005 #or .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54018ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg reward per 1000 episodes\n",
      "1000 : 0.19500000000000015\n",
      "2000 : 0.47100000000000036\n",
      "3000 : 0.5440000000000004\n",
      "4000 : 0.4940000000000004\n",
      "5000 : 0.4880000000000004\n",
      "6000 : 0.5210000000000004\n",
      "7000 : 0.5470000000000004\n",
      "8000 : 0.46700000000000036\n",
      "9000 : 0.47000000000000036\n",
      "10000 : 0.5240000000000004\n",
      "11000 : 0.5240000000000004\n",
      "12000 : 0.4890000000000004\n",
      "13000 : 0.48000000000000037\n",
      "14000 : 0.5140000000000003\n",
      "15000 : 0.4850000000000004\n",
      "q-table\n",
      "[[1.73211729e-01 7.05297359e-02 6.88991873e-02 5.81112148e-02]\n",
      " [1.64621289e-02 6.77759942e-03 1.44131563e-03 1.61247959e-01]\n",
      " [6.19247918e-02 1.34525849e-03 2.91145828e-03 3.16872220e-02]\n",
      " [2.32222969e-02 2.90490173e-03 7.04893052e-03 4.52997110e-02]\n",
      " [1.97818527e-01 2.58163837e-03 2.89895601e-02 3.74514273e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.56284167e-02 1.09089164e-06 4.66036263e-05 5.87358682e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.19467001e-02 1.84788270e-03 2.00034000e-02 3.89250409e-01]\n",
      " [2.78551254e-02 7.96197547e-01 6.50866351e-03 4.48579072e-03]\n",
      " [6.46767334e-01 5.92048706e-03 8.43322395e-04 1.26285827e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.68375542e-02 1.39441542e-01 8.53036652e-01 2.41775204e-02]\n",
      " [2.49467319e-01 9.75741270e-01 2.19487386e-01 2.19518199e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "rewards_all_episodes=[]\n",
    "\n",
    "#Q-learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    state=env.reset()\n",
    "    done=False\n",
    "    rewards_current_episode=0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        \n",
    "        exploration_rate_threshold=random.uniform(0,1)\n",
    "        if exploration_rate_threshold > exploration_rate:\n",
    "            action=np.argmax(q_table[state,:])\n",
    "        else:\n",
    "            action=env.action_space.sample()\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        #update q-table\n",
    "        q_table[state, action]=q_table[state,action] + \\\n",
    "        learning_rate*(reward+discount_rate*np.max(q_table[new_state,:]) - q_table[state,action])\n",
    "        \n",
    "        state=new_state\n",
    "        rewards_current_episode += reward\n",
    "        \n",
    "        if done: break\n",
    "            \n",
    "    exploration_rate=min_exploration_rate +(max_exploration_rate-min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "    \n",
    "    rewards_all_episodes.append(rewards_current_episode)\n",
    "    \n",
    "\n",
    "#after all episodes\n",
    "rewards_per_thousand_episodes=np.split(np.array(rewards_all_episodes),num_episodes/1000)\n",
    "count=1000\n",
    "print('Avg reward per 1000 episodes')\n",
    "for r in rewards_per_thousand_episodes:\n",
    "    print(count,':', str(sum(r/1000)))\n",
    "    count+=1000\n",
    "\n",
    "print('q-table')\n",
    "print(q_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b69e6",
   "metadata": {},
   "source": [
    "Now to watch it play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34c3c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "You fell through the hole.\n"
     ]
    }
   ],
   "source": [
    "for episode in range(2):\n",
    "    state=env.reset()\n",
    "    done=False\n",
    "    print('Episode', episode+1, \"***\\n\\n\\n\\n\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        action = np.argmax(q_table[state,:])\n",
    "        print(action)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            clear_output(wait=True)\n",
    "            env.render()\n",
    "            if reward==1:\n",
    "                print('You reached the goal! AWESOME!!!')\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print('You fell through the hole.')\n",
    "                time.sleep(3)\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        \n",
    "    state=new_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b671aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 9.84387316e-02, 5.30953679e-02, 0.00000000e+00],\n",
       "       [1.55591289e-02, 1.53927853e-02, 1.63976664e-02, 3.05635428e-02],\n",
       "       [7.39991825e-03, 1.91580544e-02, 9.78082293e-03, 2.00496930e-02],\n",
       "       [1.02737735e-02, 5.65908111e-03, 1.71923051e-03, 2.09966914e-02],\n",
       "       [1.94593760e-01, 2.81938310e-03, 4.23260203e-02, 4.31782079e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.60732079e-04, 3.12689358e-06, 7.36007861e-04, 9.25999515e-07],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.27838248e-02, 4.09561223e-02, 5.44863298e-02, 1.46562617e-01],\n",
       "       [2.63873734e-02, 4.16752025e-02, 1.65742258e-02, 4.36006856e-03],\n",
       "       [1.11411153e-02, 2.86908620e-03, 4.31673576e-03, 2.02188453e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.68424241e-02, 2.64240277e-02, 5.69993195e-01, 1.62361361e-01],\n",
       "       [1.26538347e-01, 9.53871921e-01, 1.50531551e-01, 1.95888678e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[0,0]=0\n",
    "q_table[0,3]=0\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd510fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a435bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_all_episodes = []\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    # initialize new episode params\n",
    "\n",
    "    for step in range(max_steps_per_episode): \n",
    "\n",
    "    # Exploration-exploitation trade-off\n",
    "        exploration_rate_threshold = random.uniform(0, 1)\n",
    "        if exploration_rate_threshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state,:]) \n",
    "        else:\n",
    "            action = env.action_space.sample()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
